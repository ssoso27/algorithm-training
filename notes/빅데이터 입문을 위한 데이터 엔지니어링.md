# 빅데이터 입문을 위한 데이터 엔지니어링.md 

## 데이터 엔지니어링

Raw data로부터 의미있는 정보를 추출하는 과정

 - raw data : 로그

Data—Driven 한 의사결정을 하기 위한 데이터 공급을 위해.



## PV, UV

- PV(Page Views) : 하루에 들어온 총 페이지 수
- UV(Unique Views) : 하루에 들어온 (unique한) 유저의 수



## DAU, MAU

- DAU(Daily Active User) : 하루 동안 활동한 (Unique)한 유저의 수
- WAU(Weekly)
- MAU(Monthly)

뭐를 강조해서 말하고 다닐지는 그때그때 각 재서 



## 로그

- 각 항목이 탭(혹은 ,)으로 구분되어 있는 log가 있다고 가정
- 이런 원시로그를 어떻게 처리할지 고민해보자.
- 왜 필요한가?
  - 서비스가 커지고 변화함에 따라, 로그에 찍히는 정보의 종류가 바뀜

### 로그 포맷에 대한 고민

- TSV
- CSV
- JSON

TSV, CSV는 뒤로만 데이터가 추가되어야 하고 … 해서 최근은 JSON으로도 많이 함

근데 파싱은 TSV CSV가 편함;

## PV, UV는 어떻게 뽑아야 할까?

- 기준 : User ID
  - 단점 : 로그인한 회원만 체크 가능

### PV

- 접근한 모든 유저가 요청한 모든 리퀘스트의 수

- 그럼, 로그가 하루치 로그라면, 하루의 PV는?

**시간별 PV**

- 특정 시간의 PV?
  - 하루 PV/24는 좀 ㄴㄴ함; 
- 하루에 제일 트래픽이 많이 몰리는 시간은?

### UV

- 접근한 유저를 한 번씩만 체크한 수
- User ID를 뽑아서 유니크 체크 ...

**시간별 UV**

시간별 UV와 시간별 PV는 엄청 다르게 나올 수 있다 



## 특정 유저가 하루에 몇 번이나 방문할까?

- if) 사용자가 새로고침빌런이라서 겁나 PV 찍었으면 이건 1개로 쳐야함?;;;
- 특정 유저가 몇 번 방문했다고 어떻게 정의해야 할까요?
  - 명확한 공통적인 기준은 없음
- 정의한 기준에 따른 사용자들의 하루 방문 횟수를 알 수 있으므로, 이를 통해 알아내야함

### Session

세션에 따라 나눔

ex) 로그가 2분 간격으로 6번 찍히고, 세션이 10분으로 정해짐 => session: 2개

### 광고비는 어디에 더 많이 써야 할까?

- **결제한 사람이 가장 많이 타고 들어온 매체!**
  - 절대적인건 아님… 걍 사람들 많이 들어온 매체 하던가...
- url 샘플
  - /api/v2/goods?from=naver // naver에서 왔넹!

## Data Source 

- 데이터가 어디에 있는가?
- 데이터를 어디서 가져올까?
- 파일, RDB 등등 … 

### ETL (Extract, Transform, Load)

> 정보들을 데이터 소스로부터 읽어서 (추출)
>
> 원하는 형태로 변환하고 (변환)
>
> 전환하는 것 (적재)

- ETL 과정들...

  - 세션 카운트

  - 추천

  - UV / PV

  - 수익 특정

## Data Pipeline

- ETL 잡을 순서대로 배치해서 돌려보자?
- 각각의 파이프는 자신만의 결과물을 가진다. 
- 뭔가 필요한 데이터들을 단계별로 만들고, 이용하기 위해서 만들어진 작업들을 관리하기 위한 것
- 하다보면 겁내 많은 파이프라인이 생김 … ㅠㅠ ->**관리 프로세스 필요**

### Data Pipeline 워크플로우 관리의 필요성

작업을 특정 시간에 실행 시키려면?

작업에 의존성이 있다면? (ex: 무조건 A 끝나고 B를 함 )

작업이 중간에 실패하면?

### 데이터 워크플로우 관리 툴

- Pinball, Airflow, Luigi
  - 특정 시간 실행
  - 의존성 처리
  - 실패했을 떄 반복
    - n번 쯤 해보고 실패로 판단하고 알려줌

## 데이터가 많아지면서 문제가 생기는 부분

- 데이터 수집

- 데이터 처리(정제, 변환)

- 데이터 저장

  ==> 모든 부분에 문제가 발생!!

### 데이터 수집에서의 문제점

- 많은 양의 데이터 소스 관리해야함

  - DB에도 있고 로그에도 있는데 둘이 달라! …누가 진짤까?
  - => Data Lake 같은 개념이 나옴 (모든 데이터를 걍 하둡이나 S3 이런데 저장해버리자!)

- 데이터의 스키마 자주 변경됨

- 대용량 스토리지 필요

- 정형 데이터 vs 비정형 데이터

- 배치 작업 vs 실시간 스트리밍 작업

  ####현재의 기술들

  - 로그 수집
    - Logstash
    - fluentd
    - syslogd
  - 로그 저장
    - hdfs(hadoop)
    - Kafka
    - RDBMS
    - 클라우드 스토리지 (ex: AWS)

### 데이터 처리에서의 문제점

- 많은 양의 데이터를 한 대에서 처리 불가 

  - => **분산처리** 필요
  - ==> 한대에서 처리하던거 보다 매우 **복잡**해짐 ㅠ 
  - Bucket Sort?

  #### 현재의 기술들

  - 여전히 사이징 이슈는 있음
  - SQL 기반
    - 특정 툴의 특정 기능 못 쓰는 경우도 있음
    - SparkSQL, 하이브, 레드시프트, ...
  - 코드 기반 
    - 직접 짬
    - HadoopMR, Spark

### 데이터 저장에서의 문제점

처리한 데이터를 빠르게 서빙하기 위한 저장소 필요

- ETL 결과를 다시 다른 ETL 입력으로 사용?

##Data Pipeline 관리의 어려움

- 파이프라인이 계속 재시작되어야 함 -> 전체 처리용량 부족할 수 있음 ; 
- 하루에 대한 작업이 하루내로 안해결되면?
- 재시작이 코드 버그를 해결해주진 않음 ㅠ; 

### 데이터 파이프라인 설계 지침

- 모든 워크플로우 작업은 idempotent 해야한다
  - 몇 번을 돌리든 다 같은 결과!
  - 중복된 데이터를 넣지 않는다; (이전 데이터에 대한 처리 필요!)
- 모든 워크플로우는 필요한 정보는 주입 받아야 한다
- 에러나 예외사항에 대한 정보 제공되어야 한다
  - 성공이라고 봤는데 알고보니 저장 안되고 있을 수도 있음 ㅠ 

## 데이터 엔지니어링

- 이건 누가 제안하고 설치하고 관리해야 할까? => 데이터 엔지니어!
- 데이터 엔지니어링은 경영진의 의사결정이나, 데이터 사이언티스트 등의 작업에 필요한 데이터를 공급하고, 이를 공급하는 인프라를 담당하는 역할.