# 나의삽질기록.md

## MySQL

### 이벤트 스케줄링

![image-20181024104916867](/Users/lawrence/Library/Application Support/typora-user-images/image-20181024104916867.png)

ㄴ 특정 시간에 특정 update들을 수행하는 이벤트 



**주의점**

1. MySQL timezone 과 내 local timezone(=한국시간)이 상이함

   1. MySQL timezone을 바꿔서 프로그램의 단순화를 꾀하였으나, root 권한이 없어서 실패.
   2. 따라서, 프로시저 내에 한국 시간을 나타내는 변수를 만드는 방법으로 단순화를 꾀함
      1. 한국시간 변수 @korea_now를 만듬
      2. ![image-20181024112029643](/Users/lawrence/Library/Application Support/typora-user-images/image-20181024112029643.png)
   3. 근데 권한을 받음....
   4. 한국시간으로 변경
   5. ![image-20181024151513773](/Users/lawrence/Library/Application Support/typora-user-images/image-20181024151513773.png)

2. delimiter 설정

   1. BEGIN - END 절 안의 SQL문의 구분자가 ; 이기 때문에, delimiter를 바꿔주어야 함.

3. 이벤트 스케줄러 활성화

   1. 이벤트 스케줄러가 활성화되지 않아서 이벤트가 실행되지 않음

   2. ![image-20181024112348657](/Users/lawrence/Library/Application Support/typora-user-images/image-20181024112348657.png)

   3. ~~~mysql
      SET GLOBAL event_scheduler = ON;
      ~~~

   4. 주의 : 이벤트 권한이 있는 계정으로 할 것.



### TimeZone 설정

![image-20181024151513773](/Users/lawrence/Library/Application Support/typora-user-images/image-20181024151513773.png)

**주의점**	

1. root 권한으로 TimeZone을 변경하였으나, MySQL 재접속 시 UTC로 돌아옴; 

   1. 세션시간만 바뀌어서 그런 것

   2. ![image-20181024160814911](/Users/lawrence/Library/Application Support/typora-user-images/image-20181024160814911.png)

   3. global, session 전부 바꿔주기

      1. ~~~mysql
         SET GLOBAL time_zone = 'Asia/Seoul';
         SET time_zone = 'Asia/Seoul';
         ~~~



### 소켓 에러

~~~mysql
ERROR 2002 (HY000): Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2)
~~~

**원인**

 - MYSQL의 소켓 파일인 mysql.sock 파일이 없거나 위치가 정확하지 않음.
 - 소켓파일은 /tmp/ 디렉토리에 생성됨
 - mysql이 설치되어 있지 않음

**해결**

- 그냥 서버 잘못 들어갔던 거 였음… 





## FrontEnd

### 메인화면 노출 데이터 일부가 노출되지 않음

​	![image-20181024135700395](/Users/lawrence/Library/Application Support/typora-user-images/image-20181024135700395.png)



**원인** : API호출이 가끔 TimeOut 됨

![image-20181024135748352](/Users/lawrence/Library/Application Support/typora-user-images/image-20181024135748352.png)

**해결** : API 호출했는데 오류났으면 3번까지 재호출 해봄

![image-20181024151702673](/Users/lawrence/Library/Application Support/typora-user-images/image-20181024151702673.png)

해결은 되었으나, timeout 에러다 보니, 재호출 하는데 3초가량의 시간이 듬.



## BackEnd (API)

### 잦은 API TimeOut

![image-20181025113611260](/Users/lawrence/Library/Application Support/typora-user-images/image-20181025113611260.png)

**일반적인 원인**

1. 실제로 응답을 늦게 준 경우
2. Idle timeout에 의해 연결이 강제 종료 되는 경우
3. 패킷의 생성이 늦어지는 경우
4. DB 서버단 타임아웃



**살펴볼 곳**

​	디엘의 조언 : 우리 서비스에서 타임아웃이 날만한 곳은, Gateway 혹은 Exposer에서 Repo에 접근할때가 가장 가능성이 높지 않을까?



#### **1. API Gateway**

대상 : **route가 proxy인 애들**

1. **repo 접근 로직**
   1. callDataApi
      1. getMetaByDataKey
   2. getAppByDataKeyAndApiKey
2. **redis 접근 로직**
   1. checkPreviewApiKey
   2. callDataApi
      1. get, set
      2. requestWithCache

- 로컬 게이트웨이를 띄워서, 로컬에서도 timeout인지 확인해보자!
  - 

#### 2. **리얼 DB 서버**

1. kozi-internal DB
   1. 의문 : 같은 서버의 DB인데 둘의 환경이 차이가 날 수가 있나? 

#### 3. **Data-Exposer**

1. 

## API Gateway

### 왜 인증/인가를 API Server에 구현했을까?

MSA에서 인증/인가는 보통 API Gateway에 구현하고 관리하나, 우리 서비스는 API Server에 구현하고 관리한다. 왜일까?

**우리 서비스의 API 인증/인가 주체**

| API 구분 | 설명                  | 인증/인가 주체 | Gateway 역할                      |
| -------- | --------------------- | -------------- | --------------------------------- |
| Meta     | 플랫폼 API            | API Server     | 플랫폼 API의 외부 인터페이스 제공 |
| Auth     | 플랫폼 API            | API Server     | 플랫폼 API의 외부 인터페이스 제공 |
| Proxy    | (모빌리티) 데이터 API | API Gateway    | 데이터 API의 이용 키 인증 대행    |



**이유를 생각해보자!**

 	1. 플랫폼 API와 Gateway의 분리?
 	2. 인증/인가로 인한 Gateway 과부하?
 	3. Token을 Gateway에서 까면 Back에 정보를 직접 전해줘야 해서?
 	4. API 마다 [인증 필요 여부/인가 대상자]가 달라서?



#### API 권한 인가 처리 위치 ( http://bcho.tistory.com/955 )

API에 대한 권한 인가 처리는 여러가지 계층에서 처리할 수 있다.

권한 인가는 API를 호출 하는 쪽인 클라이언트, API를 실행하는 API 서버쪽, 그리고 API 에 대한 중간 길목 역할을 하는 gateway 3군데서 처리할 수 있으며 근래에는 API 서버쪽에서 처리하는 것이 가장 일반적이다.



##### 1. Client

- 클라이언트를 신뢰할 수 있는 경우에만 사용할 수 있음.

- 기존에, 웹 UX 로직이 서버에 배치되어 있는 형태에 주로 사용.

- ![img](https://t1.daumcdn.net/cfile/tistory/256A7C40542422CD25)

- > Mobile Client는 일반 사용자만 사용한다고 가정하고, 웹 애플리케이션은 일반 사용자와 관리자 모두 사용한다고 했을 때, 일반 사용자의 Mobile Client를 위한 API Server를 별도로 배치하고, 사용자 인증(Authentication)만 되면 모든 API 호출을 허용하도록 한다. Mobile Client에 대한 API는 권한 인증에 대한 개념이 없기 때문에, 인증 처리만 하면 되고, 웹 애플리케이션의 경우에는 일반 사용자냐, 관리자냐에 따라서 권한 인가가 필요하기 때문에 아래 그림과 같이 Web Application에서, API를 호출하기 전에 사용자의 id와 권한에 따라서 API 호출 여부를 결정하는 API 권한 인가(Authorization) 처리를 하게 한다.

##### 2. GateWay

- 다양한 클라이언트 (모바일 클라이언트, 자바스크립트 기반의 웹 클라이언트) 지원됨

  ​	-> 권한 인가가 점차 서버 쪽으로 이동

  - 자바스크립트 기반의 클라이언트는 권한인가가 의미가 없음
    - 자바스크립트는 브라우저의 디버거 기능 등으로 코드 수정이 가능
    - => 권한 처리 로직 우회, 직접 API를 서버로 호출하여 권한인가 회피 등 가능

- API Gateway에 의한 권한처리는 구현이 쉽지 않아, API Server에서 권한처리 하는 것이 일반적.

- ![img](https://t1.daumcdn.net/cfile/tistory/24782340542422CE15)

- > API 호출이 들어오면, API access Token을 사용자 정보와 권한 정보로 API token management 정보를 이용해서 변환 한 후에, 접근하고자 하는 API에 대해서 권한 인가 처리를 한다.
  >
  > 이는 API 별로 API를 접근하고자 하는데 필요한 권한을 체크해야 하는데, HTTP GET /users/{id}의 API를 예로 들어보면, 이 URL에 대한 API를 호출하기 위해서는 일반 사용자 권한을 가지고 있는 사용자의 경우에는 호출하는 사용자 id와 URL상의 {id}가 일치할 때 호출을 허용하고, 같지 않을 때는 호출을 불허해야 한다.
  >
  > 만약 사용자가 관리자 권한을 가지고 있을 경우에는 호출하는 사용자 id와 URL상의 {id}가 일치하지 않더라도 호출을 허용해야 한다.

- 그러나 이러한 api gateway에서의 권한 인가는 쉽지가 않은데, 위의 /users/{id} API의 경우에는 사용자 id가 URL에 들어가 있기 때문에, API access token과 맵핑되는 사용자 ID와 그에 대한 권한을 통해서 API 접근 권한을 통제할 수 있지만, API에 따라서 사용자 id나 권한 인증에 필요한 정보가 HTTP Body에 json 형태나 HTTP Header 등에 들어가 있는 경우, 일일이 메세지 포맷에 따라서 별도의 권한 통제 로직을 gateway 단에서 구현해야 하는 부담이 있고, 권한 통제를 위해서 HTTP 메세지 전체를 일일이 파싱해야 하는 오버로드가 발생하기 때문에, 공통 필드등으로 API 권한 처리를 하지 않는 경우에는 사용하기가 어려운 부분이다.

##### 3. API Server

- 그래서 가장 일반적이고 보편적인 방법은 API 요청을 처리하는 API 서버의 비지니스 로직단에서 권한 처리를 하는 방식이다.

  이 방식은 앞에서 언급한 api gateway 방식과 비교했을때, 각 비지니스 로직에서 API 메세지를 각각 파싱하기 때문에, API 별로 권한 인가 로직을 구현하기가 용이 하다.

  이 경우에는 권한 인가에 필요한 필드들을 api gateway에서 변환해서 API 서버로 전달해줌으로써 구현을 간략하게 할 수 있는데,

- ![img](https://t1.daumcdn.net/cfile/tistory/2673FE40542422CE19)

  > API 클라이언트가 api access token을 이용해서 API를 호출했을 경우, api gateway가 이 access token을 권한 인가에 필요한 사용자 id, role등으로 변환해서 API 서버에 전달해주게 되면, 각 비지니스 로직은 API 권한 인가에 필요한 사용자 정보등을 별도로 데이타 베이스를 뒤지지 않고 이 헤더의 내용만을 이용해서 API 권한 인가 처리를 할 수 있게 된다.



### JWT Access Token 강제 만료

**만료 대상**

- 탈퇴된 회원의 Access Token
  - refresh Token은, 저장한 DB 상에서 status=2 로 관리하여서 사실상 만료처리 해둠.
- (고민중) 로그아웃 회원의 Access Token
- (고민중) 로그아웃 회원의 refresh Token



**고민 플로우**

1. 어떻게 할까?

   - JWT를 강제만료가 가능한 토큰으로 인코딩
2. 어디서 할까?

   - API Server (BackEnd)
3. 어떤 토큰으로 인코딩할까?

   - Opaque Token ? (정체를 모르겠다!)
   - 쓸 수 있는 다른 토큰을 찾아볼까...?
4. 지금 인가를 어떤 방식으로 하는가?

   - OAuth 2.0 아닐까?
5. OAuth 2.0 에서 사용할 수 있는 토큰은 어떤게 있을까?

   - spec에서의 Token 정의가 상당히 느슨하다. (= 딱히 제약 없는듯)
     - Token : 특정 사용자의 인증을 나타내는 명확하지 않은 문자열 값.
6. 근데 우리가 OAuth 2.0을 쓰는 것이 맞기는 한가?

   - 워크플로우를 보면 얼추 비슷하긴 한데… 코드 상에서 OAuth 2.0이 언급되지가 않았네...?
   - OAuth 2.0 아니래!!! 자체적으로 인가하고 있음
   - JWT는 인증용이지 인가용이 아니다!!!!!!
7. 디엘의 조언

   - 권한없는 (탈퇴된) 회원이 read를 하는건 현재로썬 문제가 없다

   - write가 좀 문제지...
   - write 되는 API 들을 찾고, 내부적으로 그걸 막아라!
8. 인가에서의 Account status check 로직을 봐볼까?

   - Account status check 로직이 존재하지 않음!
9. 어차피 인증할 때마다 Account status check 를 해야할텐데, 인증 로직에 validate 추가할까?
   - 디엘 : 왜 아무도 그렇게 구현하지 않았을까요?
   - 디엘 : 그렇게 디비에 자주 접근하면 무거워져요
   - 디엘 : 그러니까 write 하는 API에서만 체크하는게 좋을거예요
10. 각 인가로직에 다 Account status check 로직을 넣자!! ㅠㅠ 



### 기능 모듈 만들기

- 해당 기능을 쓸 장소가 어딘지 생각하기 
- abstract class로 만들고, 쓸 클래스에서 extends 시키기



### Logstash 실행

- 다음 명령어로 실행 시켜보니, 다음 에러 발생 

- ~~~
  ./bin/logstash -f logstash.conf &
  ~~~

- ~~~
  [2018-11-26T16:15:19,135][WARN ][logstash.outputs.elasticsearch] Attempted to resurrect connection to dead ES instance, but got an error. {:url=>"http://218.149.165.43:9200/", :error_type=>LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=>"Elasticsearch Unreachable: [http://218.149.165.43:9200/][Manticore::SocketException] Connection refused (Connection refused)"}
  
  2018-11-26T16:15:19,163][ERROR][logstash.outputs.elasticsearch] Failed to install template. {:message=>"Template file '' could not be found!", :class=>"ArgumentError", :backtrace=>["/logstash-6.2.4/vendor/bundle/jruby/2.3.0/gems/logstash-output-elasticsearch-9.1.1-java/lib/logstash/outputs/elasticsearch/template_manager.rb:31:in `read_template_file'", "/logstash-6.2.4/vendor/bundle/jruby/2.3.0/gems/logstash-output-elasticsearch-9.1.1-java/lib/logstash/outputs/elasticsearch/template_manager.rb:17:in `get_template'", "/logstash-6.2.4/vendor/bundle/jruby/2.3.0/gems/logstash-output-elasticsearch-9.1.1-java/lib/logstash/outputs/elasticsearch/template_manager.rb:7:in `install_template'", "/logstash-6.2.4/vendor/bundle/jruby/2.3.0/gems/logstash-output-elasticsearch-9.1.1-java/lib/logstash/outputs/elasticsearch/common.rb:96:in `install_template'", "/logstash-6.2.4/vendor/bundle/jruby/2.3.0/gems/logstash-output-elasticsearch-9.1.1-java/lib/logstash/outputs/elasticsearch/common.rb:26:in `register'", "/logstash-6.2.4/logstash-core/lib/logstash/output_delegator_strategies/shared.rb:9:in `register'", "/logstash-6.2.4/logstash-core/lib/logstash/output_delegator.rb:42:in `register'", "/logstash-6.2.4/logstash-core/lib/logstash/pipeline.rb:342:in `register_plugin'", "/logstash-6.2.4/logstash-core/lib/logstash/pipeline.rb:353:in `block in register_plugins'", "org/jruby/RubyArray.java:1734:in `each'", "/logstash-6.2.4/logstash-core/lib/logstash/pipeline.rb:353:in `register_plugins'", "/logstash-6.2.4/logstash-core/lib/logstash/pipeline.rb:730:in `maybe_setup_out_plugins'", "/logstash-6.2.4/logstash-core/lib/logstash/pipeline.rb:363:in `start_workers'", "/logstash-6.2.4/logstash-core/lib/logstash/pipeline.rb:290:in `run'", "/logstash-6.2.4/logstash-core/lib/logstash/pipeline.rb:250:in `block in start'"]}
  
  2018-11-26T16:08:55,175][FATAL][logstash.runner          ] An unexpected error occurred! {:error=>#<NoMethodError: undefined method `<' for nil:NilClass>, :backtrace=>["/logstash-6.2.4/vendor/bundle/jruby/2.3.0/gems/logstash-output-elasticsearch-9.1.1-java/lib/logstash/outputs/elasticsearch/common.rb:222:in `get_event_type'", "/logstash-6.2.4/vendor/bundle/jruby/2.3.0/gems/logstash-output-elasticsearch-9.1.1-java/lib/logstash/outputs/elasticsearch/common.rb:47:in `event_action_tuple'", "/logstash-6.2.4/vendor/bundle/jruby/2.3.0/gems/logstash-output-elasticsearch-9.1.1-java/lib/logstash/outputs/elasticsearch/common.rb:36:in `block in multi_receive'", "org/jruby/RubyArray.java:2486:in `map'", "/logstash-6.2.4/vendor/bundle/jruby/2.3.0/gems/logstash-output-elasticsearch-9.1.1-java/lib/logstash/outputs/elasticsearch/common.rb:36:in `multi_receive'", "/logstash-6.2.4/logstash-core/lib/logstash/output_delegator_strategies/shared.rb:13:in `multi_receive'", "/logstash-6.2.4/logstash-core/lib/logstash/output_delegator.rb:49:in `multi_receive'", "/logstash-6.2.4/logstash-core/lib/logstash/pipeline.rb:477:in `block in output_batch'", "org/jruby/RubyHash.java:1343:in `each'", "/logstash-6.2.4/logstash-core/lib/logstash/pipeline.rb:476:in `output_batch'", "/logstash-6.2.4/logstash-core/lib/logstash/pipeline.rb:428:in `worker_loop'", "/logstash-6.2.4/logstash-core/lib/logstash/pipeline.rb:386:in `block in start_workers'"]}
  
  ~~~

- 엘라스틱서치와 연동  문제인 듯 하여, 엘라스틱서치부터 켜보자

### Elastic search 실행

- 실행 시 다음의 에러 발생

- ~~~ 
  [1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536]
  [2]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
  
  ~~~

- vm.max_map_count

  - 프로세스가 사용할 수 있는 메모리 맵 영역의 최대 수 
  - 기본값 : 65530 (적절!)

### linux 계정 별 프로세스 제한 확인 

- 각 계정마다, 하나의 프로세스가 가질 수 있는 file descriptor에 제한이 있다.

- 종류

  - Soft limit

    - 새로운 프로그램이 생성되면, 디폴트로 적용되는 제한 값

    - ~~~
      $ ulimit -aS
      또는
      $ ulimit -a
      ~~~

  - Hard limit

    - Soft limit으로부터 늘릴 수 있는 최대 값

    - root만 고정이 가능

    - 무제한으로 늘릴 수 없다.

    - ~~~
      $ ulimit -aH
      ~~~

### linux 용량 튜닝

1. 일시적 설정

   - proc 파일 시스템에서 해당 파일에 원하는 값을 echo 명령어로 실행

   - ~~~
     $ echo 1 > /proc/sys/vm/overcommit_memory
     ~~~

   - 각 매개변수는 proc 파일 시스템에 있는 <u>/proc/sys/vm</u>에 있음

2. 영구적 설정

   - sysctl 명령어 사용 (런타임 중 커널 파라미터 설정 도구)

     ~~~
     $ sysctl -w fs.file-max=262114
     ~~~


